---
title: 'Axon Base'
icon: "brain-circuit"
description: 'Super Intelligent model for general purpose with deep reasoning'
tag: "NEW"
og:title: "Axon Base Model By MatterAI | MatterAI Documentation"
og:description: "Axon Base Model By MatterAI is a super intelligent model for general purpose with deep reasoning"
og:image: "https://res.cloudinary.com/dxvbskvxm/image/upload/v1758261129/axon-base_auegfz.png"
og:url: "https://docs.matterai.so/axon-base"
---
Axon offers secure, production-ready AI models for general-purpose tasks, leveraging advanced reasoning and organizational learning on GCP infrastructure.

<Tip>
Axon models are currently in beta with free 5M tokens, collectively for all Axon Models.
</Tip>

# Models

## Axon Base

<Frame>
  <img src="/images/axon/axon-base.png" className="block" />
</Frame>

| Specification | Value |
|---------------|-------|
| ModelID | `axon-base` |
| Description | `General purpose LLM Model with deep-reasoning` |
| Region | `US` |
| Context Window Size | `256K tokens` |
| Max Output Tokens | `16,384` |
| Input Price (`<256K`) | `$0.80/1M token` |
| Output Price (`<256K`) | `$2.00/1M tokens` |
| Input Modalities | `Text`, `Image` |
| Output Modalities | `Text` |
| Capabilities | `Function Calling`, `Tool Calling`, `Reasoning` |

### Key Features

- **Advanced Reasoning**: Deep understanding and strategic planning
- **Security**: Robust protection and threat mitigation
- **Organizational Learning**: Adapts to enterprise-specific knowledge
- **Data Privacy**: Client data isolation and secure handling
- **Platform Integration**: Jira, GitHub, GitLab connectivity
- **Deep Reasoner**: Deep Reasoner Engine with search and web fetch tool calling
- **State Machine**: Manages complex workflows and transitions

## Deep Reasoner
Our State-of-the-Art Deep Reasoner Engine generates a detailed reasoning process for your requests, detects what needs to be done and how to do it, ensuring all the context is considered and the best possible solution is provided.

- **Multi-sources causal graph traversal** for inferencing across heterogeneous data sources, enabling root-cause analysis and counterfactual reasoning.
- **Dynamic symbolic grounding** via contextual ontologies to map abstract concepts into actionable knowledge representations in real time.
- **Probabilistic logic synthesis** with uncertainty quantification to evaluate solution optimality under incomplete or ambiguous input conditions.
- **Hierarchical attention over structured memory** to maintain long-range dependencies during complex, multi-step problem decomposition.
- **Meta-cognitive feedback loops** that refine internal heuristics based on outcome validation, improving future reasoning trajectories.
- **Real-time web search integration** with federated query optimization across multiple search providers for comprehensive knowledge retrieval.
- **Adaptive web content parsing** using semantic-aware scrapers that extract structured data from dynamic web sources while respecting rate limits and ToS.

<Frame>
  <img src="/images/axon/axon-deep-reasoner.png" className="block" />
</Frame>

## State Machine
Our State-of-the-Art State Machine Engine uses temporal memories to remember your continued flow of usage on what has accomplished and what needs to be completed next.

- **Hierarchical semi-Markov decision processes** (HSMDPs) for modeling variable-duration states and adaptive task sequencing.
- **Distributed state persistence with vector-clock reconciliation** to ensure consistency across asynchronous, concurrent user sessions.
- **Reinforcement learning-driven transition policies** that optimize long-term user goal completion over immediate action rewards.
- **Temporal difference learning over latent state embeddings** to predict and pre-fetch likely next states for zero-latency transitions.
- **Context-sensitive state compression** using learned subroutines to reduce combinatorial state explosion while preserving semantic fidelity.

<Frame>
  <img src="/images/axon/axon-state-machine.png" className="block" />
</Frame>
## Integration

### Get API Key

<CardGroup cols={2}>
  <Card
  title="Get API Key"
  icon="key"
  href="/management/api-keys">
  Generate a new API key
  </Card>
</CardGroup>

### API Integration Examples

<CodeGroup>

```bash cURL
curl --request POST \
  --url https://api.matterai.so/v1/chat/completions \
  --header 'Content-Type: application/json' \
  --header 'Authorization: Bearer MATTER_API_KEY' \
  --data '{
  "model": "axon-base",
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful assistant."
    },
    {
      "role": "user",
      "content": "What is Rust?"
    }
  ],
  "stream": false,
  "max_tokens": 1000,
  "reasoning": {
    "effort": "high",
    "summary": "none"
  },
  "response_format": {
    "type": "text"
  },
  "temperature": 0,
  "top_p": 1
}'
```

```javascript OpenAI NodeJS SDK
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: 'MATTER_API_KEY',
  baseURL: 'https://api.matterai.so/v1',
});

async function main() {
  const response = await openai.chat.completions.create({
    model: 'axon-base',
    messages: [
      {
        role: 'system',
        content: 'You are a helpful assistant.'
      },
      {
        role: 'user',
        content: 'What is Rust?'
      }
    ],
    stream: false,
    max_tokens: 1000,
    reasoning: {
      effort: 'high',
      summary: 'none'
    },
    response_format: {
      type: 'text'
    },
    temperature: 0,
    top_p: 1
  });

  console.log(response.choices[0].message.content);
}

main();
```

```python OpenAI Python SDK
from openai import OpenAI

client = OpenAI(
  api_key='MATTER_API_KEY',
  base_url='https://api.matterai.so/v1'
)

response = client.chat.completions.create(
  model='axon-base',
  messages=[
    {
      'role': 'system',
      'content': 'You are a helpful assistant.'
    },
    {
      'role': 'user',
      'content': 'What is Rust?'
    }
  ],
  stream=False,
  max_tokens=1000,
  reasoning={
    'effort': 'high',
    'summary': 'none'
  },
  response_format={
    'type': 'text'
  },
  temperature=0,
  top_p=1
)

print(response.choices[0].message.content)
```

</CodeGroup>
